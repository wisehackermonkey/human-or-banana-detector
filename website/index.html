<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Human or Banana?</title>
<!--   _.---._    /\\
    ./'       "--`\//
  ./              o \          .---------------------------------------.
 /./\  )______   \__ \        ( help im traped in code and cant get out!)
./  / /\ \   | \ \  \ \       /`---------------------------------------'
   / /  \ \  | |\ \  \7--- ooo ooo ooo ooo ooo ooo -->
    <style>
        body {
            /* light yellow */
            background: hsl(4, 100%, 82%);
            box-shadow: inset;
        }

        p,
        h1,
        h3,
        h6 {
            font-family: 'Courier New', Courier, monospace;
        }
        button{
            box-shadow: 12px black;
            border-radius: 5px;
        }
    </style>
</head>

<body id='bodz'>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
        // More API functions here:
        // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

        // the link to your model provided by Teachable Machine export panel
        const URL = "https://teachablemachine.withgoogle.com/models/1gjzw0LDc/";
        let RGB_RUN = false;
        let model, webcam, labelContainer, maxPredictions;
        let bodyEl = document.getElementById("bodz");

        // Load the image model and setup the webcam
        async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // or files from your local hard drive
            // Note: the pose library adds "tmImage" object to your window (window.tmImage)
            model = await tmImage.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            // Convenience function to setup a webcam
            const flip = true; // whether to flip the webcam
            webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
            await webcam.setup(); // request access to the webcam
            await webcam.play();
            window.requestAnimationFrame(loop);

            // append elements to the DOM
            document.getElementById("webcam-container").appendChild(webcam.canvas);
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
                labelContainer.appendChild(document.createElement("div"));
            }
        }
        let rgb_set = () => {
            RGB_RUN = !RGB_RUN;
            console.log(RGB_RUN)
        }
        async function loop() {
            webcam.update(); // update the webcam frame
            await predict();
            window.requestAnimationFrame(loop);
        }

        // run the webcam image through the image model
        async function predict() {
            // predict can take in an image, video or canvas html element
            const prediction = await model.predict(webcam.canvas);
            for (let i = 0; i < maxPredictions; i++) {
                const classPrediction =
                    prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                labelContainer.childNodes[i].innerHTML = classPrediction;

                if (RGB_RUN) {
                    // genete a color based off of the 0-1 float values for each 
                    // ml class ex: 
                    // me: 1.00      =  red 255
                    // Not me: 0.00  = blue 0
                    // Bannana: 0.00 =green 0
                    // val * 255 maps the output of the machine prodections to between 0-255
                    red = prediction[0].probability.toFixed(2) * 255
                    green = prediction[1].probability.toFixed(2) * 255
                    blue = prediction[2].probability.toFixed(2) * 255
                    color = `rgb(${red}, ${green}, ${blue})`;
                    bodyEl.style.background = color;
                } else {
                    // set the background to specific colors when the
                    // machine learning predicts a specific class to be above 90% confidant
                    // ex: if class banana = 91% then set background to yellow
                    if (prediction[0].probability.toFixed(2) > 0.9) {
                        bodyEl.style.background = "green";
                    }
                    if (prediction[2].probability.toFixed(2) > 0.9) {
                        bodyEl.style.background = "yellow";

                    }
                    if (prediction[1].probability.toFixed(2) > 0.9) {
                        bodyEl.style.background = "#f8695f";//stronger red color
                    }

                }

            }
        }
    </script>
    <h1>Human or Banana?</h1>
    <p>by oran collins
        <br>github.com/wisehackermonkey
        <br>oranbusiness@gmail.com
        <br>20210128
    </p>
    <h6>created using Teachable Machine Image Model</h6>
    <h3>Click start to run the human/banana detector!</h3>

    <button type="button" onclick="init()">Start</button>
    <button type="button" onclick="rgb_set()">RGB Mode</button>
    <div id="webcam-container"></div>
    <div id="label-container"></div>

</body>

</html>